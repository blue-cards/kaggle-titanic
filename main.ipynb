{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df_2=pd.read_csv('test.csv')\n",
    "df_all=pd.concat([df,df_2],sort=False)\n",
    "df_all = df_all.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch      Fare  \\\n",
      "0              1       0.0       3     0    0  22.0      1      0    7.2500   \n",
      "1              2       1.0       1     1    1  38.0      1      0   71.2833   \n",
      "2              3       1.0       3     2    1  26.0      0      0    7.9250   \n",
      "3              4       1.0       1     1    1  35.0      1      0   53.1000   \n",
      "4              5       0.0       3     0    0  35.0      0      0    8.0500   \n",
      "..           ...       ...     ...   ...  ...   ...    ...    ...       ...   \n",
      "413         1305       NaN       3     0    0  28.0      0      0    8.0500   \n",
      "414         1306       NaN       1    17    0  39.0      0      0  108.9000   \n",
      "415         1307       NaN       3     0    1  38.5      0      0    7.2500   \n",
      "416         1308       NaN       3     0    1  28.0      0      0    8.0500   \n",
      "417         1309       NaN       3     3    1  28.0      1      1   22.3583   \n",
      "\n",
      "     Embarked  \n",
      "0         0.0  \n",
      "1         1.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "..        ...  \n",
      "413       0.0  \n",
      "414       1.0  \n",
      "415       0.0  \n",
      "416       0.0  \n",
      "417       1.0  \n",
      "\n",
      "[1309 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_13636\\3248198929.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_all[\"Age\"].fillna(x, inplace=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_13636\\3248198929.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_all['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_13636\\3248198929.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_all['Name']=df_all['Name'].replace({' Mr': 0, ' Mrs': 1, ' Miss': 2,' Master': 3, ' Don': 4, ' Rev': 5, ' Dr': 6, ' Mme': 7, ' Ms': 8, ' Major': 9, ' Lady': 10, ' Sir': 11, ' Mlle': 12, ' Col': 13, ' Capt': 14, ' the Countess': 15, ' Jonkheer': 16, ' Dona': 17})\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_13636\\3248198929.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_all['Embarked']=df_all['Embarked'].replace({'S': 0, 'C': 1, 'Q': 2})\n"
     ]
    }
   ],
   "source": [
    "#name前导处理，只保留‘ ’头衔部分，注意这里有空格，下面也要有\n",
    "df_all['Name'] = df_all['Name'].str.split(',').str[1].str.split('.').str[0]\n",
    "\n",
    "\n",
    "#处理age的缺失值\n",
    "x = df_all[\"Age\"].median()\n",
    "df_all[\"Age\"].fillna(x, inplace=True)\n",
    "\n",
    "\n",
    "#处理Sex的表述\n",
    "df_all['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n",
    "\n",
    "\n",
    "#处理Nmae的表述，注意这里有空格\n",
    "df_all['Name']=df_all['Name'].replace({' Mr': 0, ' Mrs': 1, ' Miss': 2,' Master': 3, ' Don': 4, ' Rev': 5, ' Dr': 6, ' Mme': 7, ' Ms': 8, ' Major': 9, ' Lady': 10, ' Sir': 11, ' Mlle': 12, ' Col': 13, ' Capt': 14, ' the Countess': 15, ' Jonkheer': 16, ' Dona': 17})\n",
    "\n",
    "\n",
    "#处理Embarked的表述\n",
    "df_all['Embarked']=df_all['Embarked'].replace({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "\n",
    "#删除Ticket和Cabin\n",
    "df_all.drop(['Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据正则化\n",
    "scaler = MinMaxScaler()\n",
    "df_all = scaler.fit_transform(df_all)\n",
    "\n",
    "#划分数据，还原训练集和测试集\n",
    "array_trian=df_all[:891]\n",
    "array_test=df_all[891:]\n",
    "mask = ~np.isnan(array_trian).any(axis=1)\n",
    "# 删除包含 NaN 值的行\n",
    "array_trian = array_trian[mask]\n",
    "#切出标签\n",
    "y_train= array_trian[:,1]\n",
    "y_train=y_train.astype(int)\n",
    "X_train = np.delete(array_trian, 1, axis=1)\n",
    "x_test = np.delete(array_test, 1, axis=1)\n",
    "col_mean = np.nanmean(x_test, axis=0)\n",
    "\n",
    "# 查找 NaN 值的位置\n",
    "inds = np.where(np.isnan(x_test))\n",
    "\n",
    "# 将 NaN 值替换为对应列的平均值\n",
    "x_test[inds] = np.take(col_mean, inds[1])\n",
    "np.savetxt('X_train.csv', X_train, delimiter=',')\n",
    "np.savetxt('y_train.csv', y_train, delimiter=',')\n",
    "np.savetxt('x_test.csv', x_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同算法比较\n",
    "我滚回来调优了，现在决定每个算法都试一试，看看哪个效果比较好，首先是逻辑回归，kaggle得分0.555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(x_test)\n",
    "# y_pred = y_pred.astype(int)\n",
    "# length = len(y_pred)\n",
    "# print(type(y_pred))\n",
    "# print(y_pred)\n",
    "# print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是K近邻投票,在3邻居的情况下收获了0.590的评分！\n",
    "\n",
    "在8邻居的情况下直接收获0.607的最高得分！\n",
    "\n",
    "但是优化的极限差不多也到这里就结束了，再往后变成20邻居也没有质的提升了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KNeighborsClassifier(n_neighbors=20)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们运行一下支持向量机，很遗憾，只有0.535的准确率，甚至不如逻辑回归\n",
    "\n",
    " ~~可惜不是你，陪我到最后~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVC(kernel='linear')\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面登场的是随机森林算法！！！\n",
    "\n",
    "先让我们看看100棵树，得分0.739\n",
    "\n",
    "在1000棵树的时候，出现了很有意思的情况，过拟合！得分0.736\n",
    "\n",
    "那么50棵树会发生什么？欠拟合，得分只剩下0.70了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(x_test)\n",
    "rf_pred = rf_model.predict(x_test)\n",
    "y_pred=rf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "写一个好算法固然很重要，但是洗好数据更重要，数据的样本量和处理方式才是更值得讨论的话题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "     'PassengerId': df_2.PassengerId,\n",
    "     'Survived' : y_pred\n",
    " }).to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "club",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
